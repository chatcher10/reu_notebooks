{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from planet4 import io, region_data, markings\n",
    "from p4_tools import get_final_markings_counts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import root, curve_fit, leastsq\n",
    "import pdb\n",
    "import shapely.geometry as shp\n",
    "import fiona as fio\n",
    "from shapely import affinity\n",
    "from shapely.ops import cascaded_union, unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structure mostly taken from Fans_Blotches_over_time_GP_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giza_fans.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giza_season2_metadata.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>giza_season3_metadata.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giza_blotches.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0              giza_fans.csv\n",
       "1  giza_season2_metadata.csv\n",
       "2  giza_season3_metadata.csv\n",
       "3          giza_blotches.csv\n",
       "4                       Giza"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' defining input: input is a list of filenames as strings ('filename.csv'). \n",
    "input can contain information for one or more regions. For 1 region, input should contain that region's fan file, \n",
    "followed by the season 2 metadata for that region, followed by the season 3 metadata for that region, \n",
    "followed by that region's blotches file. For more than 1 region, add more filenames in the same order. \n",
    "'''\n",
    "_input_Giza = ['giza_fans.csv','giza_season2_metadata.csv','giza_season3_metadata.csv','giza_blotches.csv']\n",
    "_input_Inca = ['Inca_seasons23_fans.csv','inca_season2_metadata.csv','inca_season3_metadata.csv','Inca_seasons23_blotches.csv']\n",
    "_input_Ithaca = ['ithaca_fans.csv','ithaca_season2_metadata.csv','ithaca_season3_metadata.csv','ithaca_blotches.csv']\n",
    "_input_Manh = ['manhattan_fans.csv','manhattan_season2_metadata.csv','manhattan_season3_metadata.csv','manhattan_blotches.csv']\n",
    "\n",
    "def get_regions(_input_):\n",
    "    '''get_regions creates a dataframe to help step through the processes below. \n",
    "    note that fan and blotch file names must be identical to the ones following \n",
    "    these \"if\" statements for the function to recognize them properly'''\n",
    "    regions = pd.DataFrame(np.zeros((4,1)))\n",
    "    if _input_[0]=='giza_fans.csv':\n",
    "        regions.loc[0] = _input_[0]\n",
    "        regions.loc[1] = _input_[1]\n",
    "        regions.loc[2] = _input_[2]\n",
    "        regions.loc[3] = _input_[3]\n",
    "        regions.loc[4] = 'Giza'\n",
    "        fan_start = 10\n",
    "        blotch_start = 16\n",
    "    elif _input_[0]=='Inca_seasons23_fans.csv':\n",
    "        regions.loc[0] = _input_[0]\n",
    "        regions.loc[1] = _input_[1]\n",
    "        regions.loc[2] = _input_[2]\n",
    "        regions.loc[3] = _input_[3]\n",
    "        regions.loc[4] = 'Inca City'\n",
    "        fan_start = 494\n",
    "        blotch_start = 8\n",
    "    elif _input_[0]=='ithaca_fans.csv':\n",
    "        regions.loc[0] = _input_[0]\n",
    "        regions.loc[1] = _input_[1]\n",
    "        regions.loc[2] = _input_[2]\n",
    "        regions.loc[3] = _input_[3]\n",
    "        regions.loc[4] = 'Ithaca'\n",
    "        fan_start = 11\n",
    "        blotch_start = 2000\n",
    "    elif _input_[0]=='manhattan_fans.csv':\n",
    "        regions.loc[0] = _input_[0]\n",
    "        regions.loc[1] = _input_[1]\n",
    "        regions.loc[2] = _input_[2]\n",
    "        regions.loc[3] = _input_[3]\n",
    "        regions.loc[4] = 'Manhattan'\n",
    "        fan_start = 811\n",
    "        blotch_start = 16626\n",
    "    return regions,fan_start,blotch_start\n",
    "\n",
    "# fan_start and blotch_start are arbitrary indexes that I found to give good example plots. I tried random integers and settled on values that gave nicely clustered objects.\n",
    "regions,fan_start,blotch_start = get_regions(_input_Giza)\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum map_scale: 1.0 ; min_fan_marking: 10.0 ; min_bl_area: 78.5398163397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chha0593/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/chha0593/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/chha0593/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/chha0593/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# read out metadata for season 2 and 3\n",
    "s2_meta = pd.read_csv(regions[0][1])\n",
    "s3_meta = pd.read_csv(regions[0][2])\n",
    "\n",
    "# read out actual markings for fans and blotches, both seasons combined\n",
    "fans = pd.read_csv(regions[0][0])\n",
    "blotches = pd.read_csv(regions[0][3])\n",
    "\n",
    "# find unique obsids in the fans and blotches catalogs\n",
    "fimg_names = fans.image_name.unique()\n",
    "bimg_names = blotches.image_name.unique()\n",
    "\n",
    "# add column for season flag and validity of marking\n",
    "fans['season'] = 0\n",
    "fans['valid_marking'] = True\n",
    "blotches['season'] = 0\n",
    "blotches['valid_marking'] = True\n",
    "blotches['area'] = np.pi * blotches.radius_1 * blotches.radius_2 / 4\n",
    "\n",
    "# define column for season flag\n",
    "fans.season[fans.obsid.str[5] == '1'] = 2\n",
    "fans.season[fans.obsid.str[5] == '2'] = 3\n",
    "blotches.season[blotches.obsid.str[5] == '1'] = 2\n",
    "blotches.season[blotches.obsid.str[5] == '2'] = 3\n",
    "\n",
    "# find what size fans should be removed for fair comparison\n",
    "min_fan_pixels = fans.distance.min()\n",
    "min_bl_area = blotches.area.min()\n",
    "\n",
    "max_scale = np.max( (s2_meta.map_scale.max(), s3_meta.map_scale.max() ) )\n",
    "print('maximum map_scale:',  max_scale, '; min_fan_marking:', min_fan_pixels, '; min_bl_area:', min_bl_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binning</th>\n",
       "      <th>invalids</th>\n",
       "      <th>l_s</th>\n",
       "      <th>line_samples</th>\n",
       "      <th>lines</th>\n",
       "      <th>map_scale</th>\n",
       "      <th>obsid</th>\n",
       "      <th>path</th>\n",
       "      <th>real_area</th>\n",
       "      <th>min_fan</th>\n",
       "      <th>min_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.925383</td>\n",
       "      <td>185.508023</td>\n",
       "      <td>41899</td>\n",
       "      <td>45359</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_011447_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>3.545212e+07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.881249</td>\n",
       "      <td>185.552493</td>\n",
       "      <td>10318</td>\n",
       "      <td>32810</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ESP_011448_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>4.020121e+07</td>\n",
       "      <td>11.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.900835</td>\n",
       "      <td>200.540424</td>\n",
       "      <td>26204</td>\n",
       "      <td>38043</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_011777_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>2.471390e+07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.898351</td>\n",
       "      <td>203.616291</td>\n",
       "      <td>25209</td>\n",
       "      <td>38913</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_011843_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>2.492830e+07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.804329</td>\n",
       "      <td>223.749771</td>\n",
       "      <td>23631</td>\n",
       "      <td>35954</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ESP_012265_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>1.039049e+07</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.811829</td>\n",
       "      <td>227.593263</td>\n",
       "      <td>25187</td>\n",
       "      <td>34687</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ESP_012344_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>1.027484e+07</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.826119</td>\n",
       "      <td>247.714498</td>\n",
       "      <td>13446</td>\n",
       "      <td>23239</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_012753_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>1.358324e+07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.598537</td>\n",
       "      <td>251.818782</td>\n",
       "      <td>15035</td>\n",
       "      <td>5288</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_012836_0850</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>7.979588e+06</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.816033</td>\n",
       "      <td>252.265089</td>\n",
       "      <td>13164</td>\n",
       "      <td>17244</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ESP_012845_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>1.044013e+07</td>\n",
       "      <td>21.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.845716</td>\n",
       "      <td>221.182466</td>\n",
       "      <td>33087</td>\n",
       "      <td>41346</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ESP_012212_0950</td>\n",
       "      <td>/Users/klay6683/Dropbox/data/hirise/labels/ESP...</td>\n",
       "      <td>1.319142e+07</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   binning  invalids         l_s  line_samples  lines  map_scale  \\\n",
       "0        4  0.925383  185.508023         41899  45359       0.50   \n",
       "1        4  0.881249  185.552493         10318  32810       1.00   \n",
       "2        2  0.900835  200.540424         26204  38043       0.50   \n",
       "3        2  0.898351  203.616291         25209  38913       0.50   \n",
       "4        4  0.804329  223.749771         23631  35954       0.25   \n",
       "5        2  0.811829  227.593263         25187  34687       0.25   \n",
       "6        2  0.826119  247.714498         13446  23239       0.50   \n",
       "7        2  0.598537  251.818782         15035   5288       0.50   \n",
       "8        2  0.816033  252.265089         13164  17244       0.50   \n",
       "9        4  0.845716  221.182466         33087  41346       0.25   \n",
       "\n",
       "             obsid                                               path  \\\n",
       "0  ESP_011447_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "1  ESP_011448_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "2  ESP_011777_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "3  ESP_011843_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "4  ESP_012265_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "5  ESP_012344_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "6  ESP_012753_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "7  ESP_012836_0850  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "8  ESP_012845_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "9  ESP_012212_0950  /Users/klay6683/Dropbox/data/hirise/labels/ESP...   \n",
       "\n",
       "      real_area  min_fan  min_bl  \n",
       "0  3.545212e+07     21.0   315.0  \n",
       "1  4.020121e+07     11.0    79.0  \n",
       "2  2.471390e+07     21.0   315.0  \n",
       "3  2.492830e+07     21.0   315.0  \n",
       "4  1.039049e+07     41.0  1257.0  \n",
       "5  1.027484e+07     41.0  1257.0  \n",
       "6  1.358324e+07     21.0   315.0  \n",
       "7  7.979588e+06     21.0   315.0  \n",
       "8  1.044013e+07     21.0   315.0  \n",
       "9  1.319142e+07     41.0  1257.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the minimal fan marking tool is = 10 pixels at max_bin = 4, it will correspond to  \n",
    "# min_fan_pixels * max_binning / image_binning\n",
    "s2_meta['min_fan'] = min_fan_pixels * s2_meta.map_scale.max() // s2_meta.map_scale + 1\n",
    "s3_meta['min_fan'] = min_fan_pixels * s3_meta.map_scale.max() // s3_meta.map_scale + 1\n",
    "\n",
    "# if the minimal blotch marking tool is = 80 sq. pixels at max_bin = 4, it will correspond to  \n",
    "# min_bl_area * max_binning^2 / image_binning^2\n",
    "s2_meta['min_bl'] = min_bl_area * s2_meta.map_scale.max()**2 // s2_meta.map_scale**2 + 1\n",
    "s3_meta['min_bl'] = min_bl_area * s3_meta.map_scale.max()**2 // s3_meta.map_scale**2 + 1\n",
    "s2_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chha0593/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# mark \"valid_marking\" key to be False for blotch markings smaller than min_bl for that image\n",
    "for i in range(len(blotches)):\n",
    "    if (blotches.season[i] == 2): \n",
    "        nr_image =  np.where(s2_meta.obsid == blotches.obsid[i])[0][0]        \n",
    "        min_b = s2_meta.min_bl[ nr_image  ]         \n",
    "        if (blotches.area[i] < min_b ):\n",
    "            blotches.valid_marking[i] = False\n",
    "    if (blotches.season[i] == 3): \n",
    "        nr_image =  np.where(s3_meta.obsid == blotches.obsid[i])[0][0]        \n",
    "        min_bl = s3_meta.min_bl[ nr_image  ]         \n",
    "        if (blotches.area[i] < min_b ):\n",
    "            blotches.valid_marking[i] = False\n",
    "            \n",
    "# mark \"valid_marking\" key to be False for fan markings smaller than min_fan for that image\n",
    "for i in range(len(fans)):\n",
    "    if (fans.season[i] == 2): \n",
    "        nr_image =  np.where(s2_meta.obsid == fans.obsid[i])[0][0]        \n",
    "        min_f = s2_meta.min_fan[ nr_image  ]         \n",
    "        if (fans.distance[i] < min_f ):\n",
    "            fans.valid_marking[i] = False\n",
    "    if (fans.season[i] == 3): \n",
    "        nr_image =  np.where(s3_meta.obsid == fans.obsid[i])[0][0]        \n",
    "        min_f = s3_meta.min_fan[ nr_image  ]         \n",
    "        if (fans.distance[i] < min_f ):\n",
    "            fans.valid_marking[i] = False\n",
    "\n",
    "fans.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next cell creates dataframe for all objects in both seasons, puts both seasons of metadata together, and adds columns for coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only valid markings are selected for the objects dataframe\n",
    "objects = pd.DataFrame({'name':pd.concat((fans.image_name[fans.valid_marking==True],blotches.image_name[blotches.valid_marking==True])),'type':np.zeros(len(fans.valid_marking[fans.valid_marking==True])+len(blotches.valid_marking[blotches.valid_marking==True])),'long':pd.concat((fans.distance[fans.valid_marking==True],blotches.radius_1[blotches.valid_marking==True])),'short':pd.concat((fans.spread[fans.valid_marking==True],blotches.radius_2[blotches.valid_marking==True])),'x':pd.concat((fans.image_x[fans.valid_marking==True],blotches.image_x[blotches.valid_marking==True])),'y':pd.concat((fans.image_y[fans.valid_marking==True],blotches.image_y[blotches.valid_marking==True])),'angle':pd.concat((fans.angle[fans.valid_marking==True],blotches.angle[blotches.valid_marking==True])),'binning':np.zeros(len(fans.valid_marking[fans.valid_marking==True])+len(blotches.valid_marking[blotches.valid_marking==True])),'l_s':np.zeros(len(fans.valid_marking[fans.valid_marking==True])+len(blotches.valid_marking[blotches.valid_marking==True])),'x_angle':pd.concat((fans.x_angle[fans.valid_marking==True],blotches.x_angle[blotches.valid_marking==True])),'y_angle':pd.concat((fans.y_angle[fans.valid_marking==True],blotches.y_angle[blotches.valid_marking==True]))}).reset_index(drop=True)\n",
    "img_unique = objects.name.unique()\n",
    "meta = pd.concat((s2_meta,s3_meta)).reset_index(drop=True)\n",
    "meta['coverage'] = 0\n",
    "meta['coverage_redundant'] = 0\n",
    "meta['season'] = 0\n",
    "meta.iloc[:len(s2_meta),13] = 2\n",
    "meta.iloc[len(s2_meta):,13] = 3\n",
    "\n",
    "#these two should be the same\n",
    "print(len(objects))\n",
    "print(len(fans.valid_marking[fans.valid_marking==True])+len(blotches.valid_marking[blotches.valid_marking==True]))\n",
    "\n",
    "#add column for binning and l_s\n",
    "for k in range(img_unique.size):\n",
    "    objects.iloc[np.where(objects.name==img_unique[k])[0],2] = np.asarray(meta.iloc[np.where(meta.obsid==img_unique[k])[0],2])\n",
    "    objects.iloc[np.where(objects.name==img_unique[k])[0],1] = np.asarray(meta.iloc[np.where(meta.obsid==img_unique[k])[0],0])\n",
    "    objects.loc[:len(fans.valid_marking[fans.valid_marking==True]),'type'] = 'f'\n",
    "    objects.loc[len(fans.valid_marking[fans.valid_marking==True]):,'type'] = 'b'\n",
    "    \n",
    "objects.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next cell creates list to be filled with shapely polygons. for fans, shapes are given by an isosceles triangle with a 13-point-approximated semi circle on top (ice cream cone), rotated about the bottom of the cone according to \"angle\". For blotches, shapes are given by a circle scaled according to the two radii \"radius_1\" and \"radius_2\", now \"long\" and \"short,\" and rotated about center according to \"angle.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [None] * len(objects)\n",
    "points = [None] * 14\n",
    "areas = np.zeros(len(objects))\n",
    "\n",
    "#re-sort objects according to image, so that blotches and fans for the same image won't be split up\n",
    "objects = objects.sort_values(by='name').reset_index(drop=True)\n",
    "meta = meta.sort_values(by='obsid').reset_index(drop=True)\n",
    "\n",
    "#loop through all objects\n",
    "for k in range(len(objects)):\n",
    "    #select for fans vs. blotches\n",
    "    if objects.type[k]=='f':\n",
    "        #multiply length of fan by binning\n",
    "        objects.iloc[k,3] = objects.iloc[k,3]*float(objects.iloc[k,1])\n",
    "        #get radius of the semi-circle\n",
    "        r = objects.long[k]*np.tan((objects.short[k]/2.)*np.pi/180.)*(1./np.sqrt(2))*(1./np.sin(((objects.short[k]/2.)+45)*np.pi/180.))*np.sin((90-(objects.short[k]/2.))*np.pi/180.)\n",
    "        red_ax = objects.long[k] - r\n",
    "        #bottom of cone\n",
    "        points[0] = (objects.x[k],objects.y[k])\n",
    "        #second point (part of triangle, base of semi-circle), going ccw from here\n",
    "        points[1] = (objects.x[k] + r,objects.y[k] + red_ax)\n",
    "        #next 11 points are on semi-cirlce\n",
    "        points[2] = (objects.x[k] + r*np.cos(15.*np.pi/180.),objects.y[k] + r*np.sin(15.*np.pi/180.) + red_ax)\n",
    "        points[3] = (objects.x[k] + r*np.cos(30.*np.pi/180.),objects.y[k] + r*np.sin(30.*np.pi/180.) + red_ax)\n",
    "        points[4] = (objects.x[k] + r*np.cos(45.*np.pi/180.),objects.y[k] + r*np.sin(45.*np.pi/180.) + red_ax)\n",
    "        points[5] = (objects.x[k] + r*np.cos(60.*np.pi/180.),objects.y[k] + r*np.sin(60.*np.pi/180.) + red_ax)\n",
    "        points[6] = (objects.x[k] + r*np.cos(75.*np.pi/180.),objects.y[k] + r*np.sin(75.*np.pi/180.) + red_ax)\n",
    "        points[7] = (objects.x[k] + r*np.cos(90.*np.pi/180.),objects.y[k] + r*np.sin(90.*np.pi/180.) + red_ax)\n",
    "        points[8] = (objects.x[k] + r*np.cos(105.*np.pi/180.),objects.y[k] + r*np.sin(105.*np.pi/180.) + red_ax)\n",
    "        points[9] = (objects.x[k] + r*np.cos(120.*np.pi/180.),objects.y[k] + r*np.sin(120.*np.pi/180.) + red_ax)\n",
    "        points[10] = (objects.x[k] + r*np.cos(135.*np.pi/180.),objects.y[k] + r*np.sin(135.*np.pi/180.) + red_ax)\n",
    "        points[11] = (objects.x[k] + r*np.cos(150.*np.pi/180.),objects.y[k] + r*np.sin(150.*np.pi/180.) + red_ax)\n",
    "        points[12] = (objects.x[k] + r*np.cos(165.*np.pi/180.),objects.y[k] + r*np.sin(165.*np.pi/180.) + red_ax)\n",
    "        #last point, third point of triangle and other base point for semi-circle, connects to first point\n",
    "        points[13] = (objects.x[k] + r*np.cos(180.*np.pi/180.),objects.y[k] + r*np.sin(180.*np.pi/180.) + red_ax)\n",
    "        #define these points as a polygon in in collections\n",
    "        collection[k] = shp.Polygon(points[:])\n",
    "        #rotate polygon about first point according to angle\n",
    "        collection[k] = affinity.rotate(collection[k],angle=objects.angle[k] - 90.,origin=points[0])\n",
    "        #record area of each object\n",
    "        areas[k] = collection[k].area\n",
    "    else:\n",
    "        #multiply both radii of blotch by binning\n",
    "        objects.iloc[k,3] = objects.iloc[k,3]*float(objects.iloc[k,1])\n",
    "        objects.iloc[k,5] = objects.iloc[k,5]*float(objects.iloc[k,1])\n",
    "        #define unit circle at center of blotch\n",
    "        circle = shp.point.Point(objects.x[k],objects.y[k]).buffer(1)\n",
    "        #stretch unit circle according to semi-major and semi-minor axes of ellipse\n",
    "        collection[k] = affinity.scale(circle,objects.long[k],objects.short[k])\n",
    "        collection[k] = affinity.rotate(collection[k],angle=objects.angle[k])\n",
    "        #record area\n",
    "        areas[k] = collection[k].area\n",
    "\n",
    "#example plots of fans \n",
    "plt.subplot(121)\n",
    "plt.plot(collection[fan_start].exterior.xy[0],collection[fan_start].exterior.xy[1])\n",
    "plt.plot(collection[fan_start+1].exterior.xy[0],collection[fan_start+1].exterior.xy[1])\n",
    "plt.plot(collection[fan_start+2].exterior.xy[0],collection[fan_start+2].exterior.xy[1])\n",
    "plt.axis('equal')\n",
    "\n",
    "#example plots of blotches\n",
    "plt.subplot(122)\n",
    "plt.plot(collection[len(objects) - (blotch_start)].exterior.xy[0],collection[len(objects) - (blotch_start)].exterior.xy[1])\n",
    "plt.plot(collection[len(objects) - (blotch_start+1)].exterior.xy[0],collection[len(objects) - (blotch_start+1)].exterior.xy[1])\n",
    "plt.plot(collection[len(objects) - (blotch_start+2)].exterior.xy[0],collection[len(objects) - (blotch_start+2)].exterior.xy[1])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, unions are calculated for the objects in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through images\n",
    "for k in range(len(meta)):\n",
    "    if k==0:\n",
    "        #get number of objects for a particular image\n",
    "        ind = len(np.where(objects.name==meta.obsid[k])[0])\n",
    "        #index to that number for the first iteration, calculate union of all objects in that image\n",
    "        meta.iloc[k,11] = unary_union(collection[:ind]).area\n",
    "    else:\n",
    "        #recall previous index, this will be the lower range for all other iterations\n",
    "        ind_minus = ind\n",
    "        #upper range is lower range plus number of objects in current image\n",
    "        ind = ind_minus + len(np.where(objects.name==meta.obsid[k])[0])\n",
    "        #index from lower to upper range, calculate union of all objects in that image\n",
    "        meta.iloc[k,11] = unary_union(collection[ind_minus:ind]).area\n",
    "    #calculate sum of areas of all objects in an image for comparison (not paying attention to overlap), store as coverage_redundant\n",
    "    meta.iloc[k,12] = np.sum(areas[np.where(objects.name==meta.obsid[k])[0]])\n",
    "    \n",
    "#example plot of objects overlapping\n",
    "plt.subplot(121)\n",
    "plt.plot(collection[fan_start].exterior.xy[0],collection[fan_start].exterior.xy[1])\n",
    "plt.plot(collection[fan_start+1].exterior.xy[0],collection[fan_start+1].exterior.xy[1])\n",
    "plt.plot(collection[fan_start+2].exterior.xy[0],collection[fan_start+2].exterior.xy[1])\n",
    "plt.axis('equal')\n",
    "\n",
    "#example plot of union of  those objects\n",
    "union = unary_union(collection[fan_start:fan_start+3])\n",
    "plt.subplot(122)\n",
    "plt.plot(union.exterior.xy[0],union.exterior.xy[1])\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "#print sum of areas of these objects\n",
    "print(np.sum(areas[fan_start:fan_start+3]))\n",
    "\n",
    "#print area of union of these objects, should be less than sum of areas\n",
    "print(unary_union(collection[fan_start:fan_start+3]).area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one plot is produced for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "#dataframes are sorted by image name, meaning season 2 will be first and season 3 second, so indexing to the size of the s2_meta array will ensure only season 2 is plotted here\n",
    "plt.scatter(meta.l_s[:len(s2_meta)],meta.coverage[:len(s2_meta)])\n",
    "#set same x axis for both, scale according to min/max l_s\n",
    "plt.xlim((min(meta.l_s)-10,max(meta.l_s)+10))\n",
    "#set same y axis for both, scale according to maximum coverage value\n",
    "plt.ylim((0,max(meta.coverage)*1.1))\n",
    "plt.title('S2 Covered Area - {}'.format(regions[0][4]))\n",
    "plt.xlabel('L_s (degrees)')\n",
    "plt.ylabel('Covered Area (pixels*binning)')\n",
    "plt.subplot(122)\n",
    "plt.scatter(meta.l_s[len(s2_meta):],meta.coverage[len(s2_meta):])\n",
    "plt.xlim((min(meta.l_s)-10,max(meta.l_s)+10))\n",
    "plt.ylim((0,max(meta.coverage)*1.1))\n",
    "plt.title('S3 Covered Area - {}'.format(regions[0][4]))\n",
    "plt.xlabel('L_s (degrees)')\n",
    "plt.ylabel('Covered Area (pixels*binning)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
